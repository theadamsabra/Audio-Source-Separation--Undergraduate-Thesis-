{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "\n",
    "- [x] Import hdf5 file as np.array\n",
    "\n",
    "[ ] Build rough draft of U-Net model\n",
    "\n",
    "[ ] Make code more reusable/object oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.nn import leaky_relu, relu, sigmoid\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `librosa` shapes the output arrays slightly differently than we want. `128` represents the number of mel coefficients we have $\\implies$ that should be in `array.shape[2]` rather than where it is now in `array.shape[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('x.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be \"training\" on a subset of the training to verify that the model actually works. Once complete, we will run it on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGING VOICE SEPARATION WITH DEEP U-NET CONVOLUTIONAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Our implementation of U-Net is similar to that of [11].\n",
    "Each encoder layer consists of a strided 2D convolution\n",
    "of stride 2 and kernel size 5x5, batch normalization, and\n",
    "leaky rectified linear units (ReLU) with leakiness 0.2. In\n",
    "the decoder we use strided deconvolution (sometimes re-\n",
    "ferred to as transposed convolution) with stride 2 and ker-\n",
    "nel size 5x5, batch normalization, plain ReLU, and use\n",
    "50% dropout to the first three layers, as in [11]. In the final\n",
    "layer we use a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:(5, 128, 4102) \n",
      " Output Shape: (5, 128, 4102)\n"
     ]
    }
   ],
   "source": [
    "# Train on 5 to ensure code scales.\n",
    "print(f'Input Shape:{x.shape} \\n Output Shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    dilation_rate=(1, 1), groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel_size\n",
    "- strides\n",
    "- padding\n",
    "- activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalUNet(tf.keras.Model):\n",
    "    def __init__(self, kernel_size = (5,5), strides = (2,2)):\n",
    "        # Initialize Model properties\n",
    "        super(VocalUNet, self).__init__()\n",
    "        '''\n",
    "        VocalUNet is the linked paper above translated into Keras Model classes.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - kernel_size: (tuple/list)\n",
    "        Size of kernel for model. Default set to (5,5).\n",
    "\n",
    "        - strides: (tuple/list)\n",
    "        Size of stride of kernel. Default set to (2,2).\n",
    "        \n",
    "        A Note on Batch Normalization and Dropout layers:\n",
    "        ------------------------------------------------\n",
    "        Batch Normalization and Dropouts are used throughout the\n",
    "        convolution and convolution transpose. Syntax among the \n",
    "        TensorFlow Model Classes dictates that these layers - even\n",
    "        if the same - are initalized numerous times. However, in \n",
    "        the Vocal U-Net, these layers are the same. I will initalize\n",
    "        them once and reuse them throughout the call() function.\n",
    "        \n",
    "        NOTES:\n",
    "        - need to know what to do with training paramter for dropout.\n",
    "        '''\n",
    "        # Batch Normalization layer:\n",
    "        self.bn = BatchNormalization()\n",
    "        # Dropout layer:\n",
    "        self.dropout = Dropout(0.5)\n",
    "        # First Convolution\n",
    "        self.conv1 = Conv2D(filters = 16, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Second Convolution\n",
    "        self.conv2 = Conv2D(filters = 32, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Third Convolution\n",
    "        self.conv3 = Conv2D(filters = 64, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Fourth Convolution\n",
    "        self.conv4 = Conv2D(filters = 128, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Fifth Convolotion\n",
    "        self.conv5 = Conv2D(filters = 256, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Sixth Convolution\n",
    "        self.conv6 = Conv2D(filters = 512, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        '''\n",
    "        Deconvolve/Convolution Transpose layers:\n",
    "        As we deconvolve the layers, we dropout half for the first three\n",
    "        deconvolution layers. The rest follows typical procedure of\n",
    "        deconvoloution with sigmoid activation function.\n",
    "        '''\n",
    "        # Convolution Transpose 1:\n",
    "        self.convt1 = Conv2DTranspose(filters = 256, kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 2:\n",
    "        self.convt2 = Conv2DTranspose(filters = 128,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 3:\n",
    "        self.convt3 = Conv2DTranspose(filters = 64,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 4:\n",
    "        self.convt4 = Conv2DTranspose(filters = 32,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 5:\n",
    "        self.convt5 = Conv2DTranspose(filters = 16,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 6:\n",
    "        self.convt6 = Conv2DTranspose(filters = 1, kernel_size = kernel_size,\n",
    "        strides = strides, activation = sigmoid)\n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        Again, typical syntax on TensorFlow would prefer x as the variable\n",
    "        name. However, if I keep this syntax below, concatenating specific\n",
    "        layers will be a mess. To avoid this, I will name each layer in the\n",
    "        forward pass as l1, l2, etc.\n",
    "        '''\n",
    "        l1 = self.bn(self.conv1(inputs))\n",
    "        l2 = self.bn(self.conv2(l1))\n",
    "        l3 = self.bn(self.conv3(l2))\n",
    "        l4 = self.bn(self.conv4(l3))\n",
    "        l5 = self.bn(self.conv5(l4))\n",
    "        l6 = self.bn(self.conv6(l5))\n",
    "        l7 = self.bn(self.convt1(l6))\n",
    "        l8 = self.dropout(l7)\n",
    "        l9 = self.bn(self.convt2(concatenate([l8, l5])))\n",
    "        l10 = self.dropout(l9)\n",
    "        l11 = self.bn(self.convt3(concatenate([l10, l4])))\n",
    "        l12 = self.dropout(l11)\n",
    "        l13 = self.bn(self.convt4(concatenate([l12, l3])))\n",
    "        l14 = self.bn(self.convt5(concatenate([l13, l2])))\n",
    "        l15 = self.convt6(concatenate([l14,l1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = VocalUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a5d3a554fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1684\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIn\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprovided\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m     \"\"\"\n\u001b[0;32m-> 1686\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1687\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_on_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_on_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Awesome error.\n",
    "# Learning the structure of these models is useful.\n",
    "unet.train_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
