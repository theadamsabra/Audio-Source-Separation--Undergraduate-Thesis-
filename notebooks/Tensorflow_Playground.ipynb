{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "\n",
    "- [x] Import hdf5 file as np.array\n",
    "\n",
    "[ ] Build rough draft of U-Net model\n",
    "\n",
    "[ ] Make code more reusable/object oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.nn import leaky_relu, relu, sigmoid\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `librosa` shapes the output arrays slightly differently than we want. `128` represents the number of mel coefficients we have $\\implies$ that should be in `array.shape[2]` rather than where it is now in `array.shape[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('x.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be \"training\" on a subset of the training to verify that the model actually works. Once complete, we will run it on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGING VOICE SEPARATION WITH DEEP U-NET CONVOLUTIONAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Our implementation of U-Net is similar to that of [11].\n",
    "Each encoder layer consists of a strided 2D convolution\n",
    "of stride 2 and kernel size 5x5, batch normalization, and\n",
    "leaky rectified linear units (ReLU) with leakiness 0.2. In\n",
    "the decoder we use strided deconvolution (sometimes re-\n",
    "ferred to as transposed convolution) with stride 2 and ker-\n",
    "nel size 5x5, batch normalization, plain ReLU, and use\n",
    "50% dropout to the first three layers, as in [11]. In the final\n",
    "layer we use a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:(5, 128, 4102) \n",
      " Output Shape: (5, 128, 4102)\n"
     ]
    }
   ],
   "source": [
    "# Train on 5 to ensure code scales.\n",
    "print(f'Input Shape:{x.shape} \\n Output Shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    dilation_rate=(1, 1), groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel_size\n",
    "- strides\n",
    "- padding\n",
    "- activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to convert np array to tf.Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocalUNet(tf.keras.Model):\n",
    "    def __init__(self, kernel_size = (5,5), strides = (2,2)):\n",
    "        # Initialize Model properties\n",
    "        super(VocalUNet, self).__init__()\n",
    "        '''\n",
    "        VocalUNet is the linked paper above translated into Keras Model classes.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - kernel_size: (tuple/list)\n",
    "        Size of kernel for model. Default set to (5,5).\n",
    "\n",
    "        - strides: (tuple/list)\n",
    "        Size of stride of kernel. Default set to (2,2).\n",
    "\n",
    "        NEED TO ADD TO INIT AND DETERMINE HOW TO USE THIS PROPERLY.\n",
    "        - training: (bool)\n",
    "        True or false for differentiating between training/testing.\n",
    "\n",
    "        NOTES:\n",
    "        - need to add BatchNormalization layers\n",
    "        - need to ensure dropout and other layers work fine\n",
    "        - need to know what to do with training paramter for dropout.\n",
    "        '''\n",
    "        # First Convolution\n",
    "        self.conv1 = Conv2D(filters = 16, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Second Convolution\n",
    "        self.conv2 = Conv2D(filters = 32, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Third Convolution\n",
    "        self.conv3 = Conv2D(filters = 64, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Fourth Convolution\n",
    "        self.conv4 = Conv2D(filters = 128, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Fifth Convolotion\n",
    "        self.conv5 = Conv2D(filters = 256, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        # Sixth Convolution\n",
    "        self.conv6 = Conv2D(filters = 512, kernel_size = kernel_size,\n",
    "        strides = strides, activation = leaky_relu)\n",
    "        '''\n",
    "        Deconvolve/Convolution Transpose layers:\n",
    "        As we deconvolve the layers, we dropout half for the first three\n",
    "        deconvolution layers. The rest follows typical procedure of\n",
    "        deconvoloution with sigmoid activation function.\n",
    "        '''\n",
    "        # Convolution Transpose 1:\n",
    "        self.convt1 = Conv2DTranspose(filters = 256, kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Dropout 1:\n",
    "        self.dropout1 = Dropout(rate = 0.5)\n",
    "        # Convolution Transpose 2:\n",
    "        self.convt2 = Conv2DTranspose(filters = 128,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Dropout 2:\n",
    "        self.dropout2 = Dropout(rate = 0.5)\n",
    "        # Convolution Transpose 3:\n",
    "        self.convt3 = Conv2DTranspose(filters = 64,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Dropout 3:\n",
    "        self.dropout3 = Dropout(rate = 0.5)\n",
    "        # Convolution Transpose 4:\n",
    "        self.convt4 = Conv2DTranspose(filters = 32,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 5:\n",
    "        self.convt5 = Conv2DTranspose(filters = 16,kernel_size = kernel_size,\n",
    "        strides = strides, activation = relu)\n",
    "        # Convolution Transpose 6:\n",
    "        self.convt6 = Conv2DTranspose(filters = 1, kernel_size = kernel_size,\n",
    "        strides = strides, activation = sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = VocalUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
