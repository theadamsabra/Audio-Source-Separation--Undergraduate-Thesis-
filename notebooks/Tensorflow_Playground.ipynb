{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "\n",
    "- [x] Import hdf5 file as np.array\n",
    "\n",
    "[ ] Build rough draft of U-Net model\n",
    "\n",
    "[ ] Make code more reusable/object oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `librosa` shapes the output arrays slightly differently than we want. `128` represents the number of mel coefficients we have $\\implies$ that should be in `array.shape[2]` rather than where it is now in `array.shape[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path, key):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        array = np.array(f[key], dtype = 'float64')\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture Shape: (233, 128, 4102) \n",
      " Target Shape: (233, 128, 4102)\n"
     ]
    }
   ],
   "source": [
    "path = '/home/asabra/GitHub/Audio-Source-Separation-Undergraduate-Thesis/data/Test.hdf5'\n",
    "# Load in hdf5 datasets as np.array\n",
    "mixture = loader(path, 'mixture')\n",
    "target = loader(path, 'target')\n",
    "\n",
    "print(f'Mixture Shape: {mixture.shape} \\n Target Shape: {target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be \"training\" on a subset of the training to verify that the model actually works. Once complete, we will run it on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture Shape:(10, 128, 4102) \n",
      " Target Shape: (10, 128, 4102)\n"
     ]
    }
   ],
   "source": [
    "testmix = mixture[:10, :, :]\n",
    "testvoc = target[:10, :, :]\n",
    "print(f'Mixture Shape:{testmix.shape} \\n Target Shape: {testvoc.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGING VOICE SEPARATION WITH DEEP U-NET CONVOLUTIONAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Our implementation of U-Net is similar to that of [11].\n",
    "Each encoder layer consists of a strided 2D convolution\n",
    "of stride 2 and kernel size 5x5, batch normalization, and\n",
    "leaky rectified linear units (ReLU) with leakiness 0.2. In\n",
    "the decoder we use strided deconvolution (sometimes re-\n",
    "ferred to as transposed convolution) with stride 2 and ker-\n",
    "nel size 5x5, batch normalization, plain ReLU, and use\n",
    "50% dropout to the first three layers, as in [11]. In the final\n",
    "layer we use a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmix = testmix.reshape(testmix.shape[0], testmix.shape[2],\n",
    "                         testmix.shape[1], 1)\n",
    "testvoc = testvoc.reshape(testvoc.shape[0], testvoc.shape[2],\n",
    "                         testvoc.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4102, 128, 1) (10, 4102, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(testmix.shape, testvoc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 4102, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(16, kernel_size = (5,5),\n",
    "                activation = 'leakyReLU',\n",
    "                input_shape = (img_rows, img_cols, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
